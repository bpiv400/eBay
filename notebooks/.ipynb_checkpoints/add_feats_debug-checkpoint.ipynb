{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_feats(feat_df):\n",
    "    # grab offer time\n",
    "    off_series = feat_df['src_cre_date'].values\n",
    "    # grab auction post time\n",
    "    post_series = feat_df['auct_start_dt'].values\n",
    "    # grab auction expiration time\n",
    "    close_series = feat_df['auct_end_dt'].values\n",
    "    close_series = close_series + np.timedelta64(24, 'h')\n",
    "\n",
    "    # get total duration in hours\n",
    "    dur = (close_series - post_series).astype(int)/1e9/math.pow(60, 2)\n",
    "\n",
    "    rem = (close_series - off_series).astype(int)/1e9/math.pow(60, 2)\n",
    "    passed = (off_series - post_series).astype(int)/1e9/math.pow(60, 2)\n",
    "\n",
    "    # creating series for each new feature\n",
    "    duration = pd.Series(dur, index=feat_df.index)\n",
    "    remain = pd.Series(rem, index=feat_df.index)\n",
    "    passed_time = pd.Series(passed, index=feat_df.index)\n",
    "    frac_passed = pd.Series(passed/dur, index=feat_df.index)\n",
    "    frac_remain = pd.Series(remain/dur, index=feat_df.index)\n",
    "\n",
    "    feat_df['frac_remain'] = frac_remain\n",
    "    feat_df['frac_passed'] = frac_passed\n",
    "    feat_df['passed'] = passed_time\n",
    "    feat_df['remain'] = remain\n",
    "    feat_df['duration'] = duration\n",
    "\n",
    "    return feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept_bool(df):\n",
    "    df.sort_values(by='src_cre_date', ascending=True,\n",
    "                   inplace=True)\n",
    "    accepted = df['status_id'].isin([1, 9]).values\n",
    "    tot = np.sum(accepted)\n",
    "    if tot > 0:\n",
    "        if tot > 1:\n",
    "            return False\n",
    "        else:\n",
    "            return accepted[len(accepted) - 1]\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accept(df, accept_series, both_inds, val):\n",
    "    accept_series.drop(index=both_inds, inplace=True)\n",
    "    big_inds = accept_series[accept_series > 1].index\n",
    "    big_inds = big_inds.values\n",
    "    if big_inds.size > 0:\n",
    "        print(big_inds)\n",
    "        df_inds = df[df['unique_thread_id'].isin(big_inds)].index\n",
    "        df.drop(index=df_inds, inplace=True)\n",
    "    accept_series.drop(index=big_inds, inplace=True)\n",
    "    remaining_threads = accept_series.index\n",
    "    remaining_threads = remaining_threads.values\n",
    "    accepted_df = df.loc[df['unique_thread_id'].isin(remaining_threads), ['status_id', 'unique_thread_id', \n",
    "                                                                         'turn_count']].copy()\n",
    "    if len(accepted_df.index) > 0:\n",
    "        num_turns = accepted_df.groupby('unique_thread_id').size()\n",
    "        accepted_df = accepted_df[accepted_df['status_id'] == val].copy()\n",
    "        accepted_df.set_index('unique_thread_id', inplace=True)\n",
    "        loc_accepted = accepted_df['turn_count']\n",
    "        num_turns = num_turns - 1\n",
    "        thread_inds = loc_accepted[num_turns != loc_accepted].index\n",
    "        thread_inds = thread_inds.values\n",
    "        print(thread_inds)\n",
    "        df_inds = df[df['unique_thread_id'].isin(thread_inds)].index\n",
    "        df.drop(index=df_inds, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_data(df):\n",
    "    df = df.copy()\n",
    "    org_ids = len(np.unique(df['unique_thread_id'].values))\n",
    "    # remove thread ids corresponding to threads where at least one offer is greater\n",
    "    # than the start price\n",
    "    larg_off = df['start_price_usd'].values < df['offr_price'].values\n",
    "    larg_off_threads = np.unique(df.loc[larg_off, 'unique_thread_id'].values)\n",
    "    print(larg_off_threads)\n",
    "    larg_off = df['unique_thread_id'].isin(larg_off_threads)\n",
    "    del larg_off_threads\n",
    "    larg_off_inds = df[larg_off].index\n",
    "    df.drop(larg_off_inds, inplace=True)\n",
    "    del larg_off\n",
    "    del larg_off_inds\n",
    "\n",
    "    print('Removed threads where one offer is greater than the start price')\n",
    "    # remove thread ids corresponding to threads where more than 6 turns have been taken\n",
    "    long_thread = df['turn_count'] > 5\n",
    "    long_thread = long_thread.values\n",
    "    long_thread_ids = np.unique(df.loc[long_thread, 'unique_thread_id'].values)\n",
    "    print(long_thread_ids)\n",
    "    long_thread = df['unique_thread_id'].isin(long_thread_ids)\n",
    "    del long_thread_ids\n",
    "    long_thread_inds = df[long_thread].index\n",
    "    df.drop(long_thread_inds, inplace=True)\n",
    "    del long_thread\n",
    "    del long_thread_inds\n",
    "\n",
    "    print('Removed threads where more than 6 offers have been made')\n",
    "\n",
    "    # filter by unique_thread_id, and remove threads where an offer is accepted\n",
    "    # but there are other offers after it\n",
    "    prev_ids = len(np.unique(df['unique_thread_id'].values))\n",
    "\n",
    "    max_turns = feat_df.groupby(['status_id', 'unique_thread_id']).size()\n",
    "    max_turns_accept = max_turns.xs(1, level='status_id', drop_level=True)\n",
    "    max_turns_auto = max_turns.xs(9, level='status_id', drop_level=True)\n",
    "    del max_turns\n",
    "    auto_inds = max_turns_auto.index\n",
    "    accept_inds = max_turns_accept.index\n",
    "    both_inds = np.intersect1d(auto_inds.values, accept_inds.values)\n",
    "    if both_inds.size > 0:\n",
    "        print(both_inds)\n",
    "        both_accept_ids = df[df['unique_thread_id'].isin(both_inds)].index\n",
    "        df.drop(both_accept_inds, inplace=True)\n",
    "    df = remove_accept(df, max_turns_accept, both_inds, 1)\n",
    "    df = remove_accept(df, max_turns_auto, both_inds, 9)\n",
    "\n",
    "    print('Removed threads that have an accepted offer but not as the last offer')\n",
    "    cut_ids = len(np.unique(df['unique_thread_id'].values))\n",
    "    print('Threads had an accept offer entered in the wrong place: %d' %\n",
    "          (prev_ids - cut_ids))\n",
    "    print('Total Removed: %d' % (org_ids - cut_ids))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_offrs_counter(df, turn):\n",
    "    prev_turn = turn - 1\n",
    "    curr_offr_inds = df[df['offr_type_id'].isin([1, 2])].xs(\n",
    "        turn, level='turn_count', drop_level=True).index\n",
    "    prev_offr_inds = [(ind, prev_turn) for ind in curr_offr_inds.values]\n",
    "    curr_offr_inds = [(ind, turn) for ind in curr_offr_inds.values]\n",
    "    prev_offrs = df.loc[prev_offr_inds, 'offr_price'].values\n",
    "    df.loc[curr_offr_inds, 'prev_offr_price'] = prev_offrs\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_offrs_init(df):\n",
    "    df.set_index('turn_count', drop=True, inplace=True)\n",
    "    byr_turns = df[df['offr_type_id'] == 0].index.values\n",
    "    slr_turns = df[df['offr_type_id'] == 2].index.values\n",
    "\n",
    "    if byr_turns.size > 0:\n",
    "        # sorting seller turn numbers\n",
    "        slr_turns = np.sort(slr_turns)\n",
    "        # if there has been at least one seller turn\n",
    "        if slr_turns.size > 0:\n",
    "            # find the indices in the slr_turns array where we can insert buyer\n",
    "            # turns to maintain order\n",
    "            # Since slr_turns[i] != byr_turns[j] \\forall i,j,  these values\n",
    "            # implicitly correspond to 1 greater than the index in slr_turns\n",
    "            # of the seller turn before each buyer turn\n",
    "            insert_points = np.searchsorted(slr_turns, byr_turns)\n",
    "        else:\n",
    "            # if there hasn't been any sellers, just make insert points all 0's\n",
    "            insert_points = np.zeros(len(byr_turns))\n",
    "        # find the indices of byrs whose insert points corresopnd to 0's\n",
    "        init_inds = byr_turns[insert_points == 0]\n",
    "        # boolean array for whether each point is nonzero\n",
    "        nonzero_inserts = insert_points != 0\n",
    "        # indices of buyers whose insert points correspond to nonzero values\n",
    "        other_inds = byr_turns[nonzero_inserts]\n",
    "        # shrinking insert points to corresopnd only to those with nonzero values\n",
    "        insert_points = insert_points[nonzero_inserts]\n",
    "        if init_inds.size > 0:\n",
    "            # setting all indices of buyers who occur before seller counter offers\n",
    "            # to have prev offer equal to starting price\n",
    "            df.loc[init_inds, 'prev_offr_price'] = df.at[0, 'start_price_usd']\n",
    "        if insert_points.size > 0:\n",
    "            # incrementing insert_points down 1, so that insert points now give\n",
    "            # the indices in slr_turns corresponding to the sellers\n",
    "            # immediately before the nonzero insert points\n",
    "            insert_points = insert_points - 1\n",
    "            # grabbing seller indices by indexing by insert_points\n",
    "            other_sellers = slr_turns[insert_points]\n",
    "            # extract previous offer values using other_sellers array\n",
    "            prev_offrs = df.loc[other_sellers, 'offr_price'].values\n",
    "            df.loc[other_inds, 'prev_offr_price'] = prev_offrs\n",
    "\n",
    "    count_nan = np.sum(np.isnan(df['prev_offr_price'].values))\n",
    "    if count_nan > 0:\n",
    "        print(df[['offr_type_id', 'status_id', 'offr_price', 'start_price_usd', \n",
    "                'prev_offr_price', 'resp_offr']])\n",
    "        raise ValueError('No NANs should escape this phase')\n",
    "    df.reset_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "def prev_offr(df):\n",
    "    # adding previous offer to initial offer\n",
    "    prev_offr = pd.Series(np.nan, index=df.index)\n",
    "    print('Adding initial offers')\n",
    "    df['prev_offr_price'] = prev_offr\n",
    "    init_offr_inds = df[df['turn_count'] == 0].index\n",
    "    start_price = df.loc[init_offr_inds, 'start_price_usd'].copy()\n",
    "    df.loc[init_offr_inds, 'prev_offr_price'] = start_price.values\n",
    "    df.set_index(['unique_thread_id', 'turn_count'], inplace=True)\n",
    "    all_turns = df.index.levels[1]\n",
    "    for i in range(1, 6):\n",
    "        if i in all_turns:\n",
    "            print('Adding turn %d' % (i + 1))\n",
    "            df = add_offrs_counter(df, i)\n",
    "    df.reset_index(inplace=True, drop=False)\n",
    "    df = df.groupby(by='unique_thread_id').apply(add_offrs_init)\n",
    "    \n",
    "    # to implement if necessary\n",
    "    # group_list = []\n",
    "    # for _, group in data:\n",
    "    #     new_group = group.copy()\n",
    "    #     new_group = add_offrs_byrs(new_group)\n",
    "    #     if new_group is not None:\n",
    "    #         group_list.append(new_group)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data/toy/toy-1_feats.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9cd397de9c49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m                       parse_dates=['src_cre_date', 'auct_start_dt',\n\u001b[0;32m      3\u001b[0m                                    'auct_end_dt', 'response_time'],\n\u001b[1;32m----> 4\u001b[1;33m                       dtype={'unique_thread_id': np.int64})\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfeat_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item_cndtn_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'meta_categ_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'anon_leaf_categ_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'src_cre_dt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfeat_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Unnamed: 0'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'turn_count'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'data/toy/toy-1_feats.csv' does not exist"
     ]
    }
   ],
   "source": [
    "feat_df = pd.read_csv('C:/Users/bpiv4/dropbox/eBay/data/' + 'toy' + '/' + 'toy-1_feats.csv',\n",
    "                      parse_dates=['src_cre_date', 'auct_start_dt',\n",
    "                                   'auct_end_dt', 'response_time'],\n",
    "                      dtype={'unique_thread_id': np.int64})\n",
    "feat_df.drop(columns=['item_cndtn_id', 'meta_categ_id', 'anon_leaf_categ_id', 'src_cre_dt'], inplace=True)\n",
    "feat_df.rename(columns={'Unnamed: 0': 'turn_count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_df = date_feats(feat_df)\n",
    "prev_df = feat_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df[['duration', 'frac_passed', 'passed', 'remain', 'frac_remain', 'frac_passed']]\n",
    "feat_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding initial offers\n",
      "Adding turn 2\n",
      "Adding turn 3\n",
      "Adding turn 4\n",
      "Adding turn 5\n",
      "Adding turn 6\n"
     ]
    }
   ],
   "source": [
    "prev_df = prev_offr(prev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    163    1969    4186 ... 4026733 4029323 4031202]\n",
      "Removed threads where one offer is greater than the start price\n",
      "[]\n",
      "Removed threads where more than 6 offers have been made\n",
      "[ 270159  717833 2475340]\n",
      "[535984]\n",
      "[]\n",
      "Removed threads that have an accepted offer but not as the last offer\n",
      "Threads had an accept offer entered in the wrong place: 4\n",
      "Total Removed: 3906\n"
     ]
    }
   ],
   "source": [
    "clean_df = clean_data(feat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_thread_id</th>\n",
       "      <th>turn_count</th>\n",
       "      <th>status_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29562</th>\n",
       "      <td>270159</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29563</th>\n",
       "      <td>270159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58951</th>\n",
       "      <td>535984</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58952</th>\n",
       "      <td>535984</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78949</th>\n",
       "      <td>717833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78950</th>\n",
       "      <td>717833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276995</th>\n",
       "      <td>2475340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276996</th>\n",
       "      <td>2475340</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        unique_thread_id  turn_count  status_id\n",
       "29562             270159           0          1\n",
       "29563             270159           1          1\n",
       "58951             535984           0          1\n",
       "58952             535984           1          8\n",
       "78949             717833           0          1\n",
       "78950             717833           1          1\n",
       "276995           2475340           0          1\n",
       "276996           2475340           1          1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = feat_df[feat_df['unique_thread_id'].isin([270159, 717833, 2475340, 535984])].index\n",
    "feat_df.loc[ind, ['unique_thread_id', 'turn_count', 'status_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
