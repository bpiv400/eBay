{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('repo/trans_probs/mvp/'))\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy.interpolate import BSpline\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from models import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'norm1_crossent_comp'\n",
    "turn = 'b0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model parameters\n",
    "model_dict = torch.load('models/exps/%s/model_%s.pth.tar' % (exp_name, turn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature dictionary\n",
    "with open('models/exps/%s/featdict_%s.pickle' % (exp_name, turn), 'rb') as f:\n",
    "    feat_dict = pickle.load(f)\n",
    "f.close()\n",
    "reverse = {}\n",
    "for col, ind in feat_dict.items():\n",
    "    reverse[ind] = col\n",
    "\n",
    "# column list...no idea why I used a dictionary for this tbh\n",
    "col_list = []\n",
    "for i in range(len(reverse)):\n",
    "    next_col = reverse[i]\n",
    "    col_list.append(next_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class series\n",
    "class_series = pd.read_csv('models/exps/%s/class_series_%s.csv' % (exp_name, turn), squeeze=True, index_col=0, header=None)\n",
    "classes = class_series.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Cross_comp\n",
    "num_features = len(col_list)\n",
    "num_units = 100\n",
    "num_classes = len(classes)\n",
    "model = net(num_features, num_units, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num features: 76\n"
     ]
    }
   ],
   "source": [
    "print('num features: %d' % num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 76])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict['fc1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_param = model_dict['fc1.weight']\n",
    "norm = test_param.norm(2, dim=1, keepdim=True)\n",
    "norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5.3829],\n",
       "        [ 13.8804],\n",
       "        [  5.5796],\n",
       "        [  2.5494],\n",
       "        [ 12.7682],\n",
       "        [  3.0317],\n",
       "        [  3.5005],\n",
       "        [  2.5529],\n",
       "        [  2.3500],\n",
       "        [ 12.7964],\n",
       "        [  1.5404],\n",
       "        [  4.0994],\n",
       "        [  5.8475],\n",
       "        [  3.5220],\n",
       "        [  2.8573],\n",
       "        [  2.6279],\n",
       "        [  2.3829],\n",
       "        [  2.2037],\n",
       "        [  2.3735],\n",
       "        [  5.9923],\n",
       "        [  2.4946],\n",
       "        [  3.7216],\n",
       "        [  1.7870],\n",
       "        [  3.3978],\n",
       "        [  6.1405],\n",
       "        [  3.8749],\n",
       "        [  1.5529],\n",
       "        [  2.7407],\n",
       "        [  2.2651],\n",
       "        [  2.4564],\n",
       "        [  2.7201],\n",
       "        [  2.9620],\n",
       "        [  4.9081],\n",
       "        [  1.8328],\n",
       "        [  2.8067],\n",
       "        [  2.0658],\n",
       "        [  1.7289],\n",
       "        [  2.8896],\n",
       "        [  2.7788],\n",
       "        [  4.1639],\n",
       "        [  3.2238],\n",
       "        [  4.2102],\n",
       "        [  3.3707],\n",
       "        [  3.1314],\n",
       "        [  3.7941],\n",
       "        [  1.9174],\n",
       "        [  4.4329],\n",
       "        [  2.8161],\n",
       "        [  2.3323],\n",
       "        [  3.4317],\n",
       "        [  3.6691],\n",
       "        [  4.2030],\n",
       "        [  2.2316],\n",
       "        [  2.9790],\n",
       "        [ 10.1375],\n",
       "        [ 11.8003],\n",
       "        [  3.5338],\n",
       "        [  3.9814],\n",
       "        [  4.2879],\n",
       "        [  2.4323],\n",
       "        [  4.6604],\n",
       "        [  2.4771],\n",
       "        [  2.6961],\n",
       "        [  4.1253],\n",
       "        [  1.4343],\n",
       "        [  9.5333],\n",
       "        [  6.0865],\n",
       "        [  2.3092],\n",
       "        [ 14.8530],\n",
       "        [  4.0816],\n",
       "        [  4.2610],\n",
       "        [  2.1469],\n",
       "        [  3.0179],\n",
       "        [  2.4746],\n",
       "        [  1.9371],\n",
       "        [  3.1615],\n",
       "        [ 10.5787],\n",
       "        [  3.6119],\n",
       "        [ 30.2794],\n",
       "        [  4.8073],\n",
       "        [  2.9273],\n",
       "        [  6.6919],\n",
       "        [  1.7830],\n",
       "        [  1.7167],\n",
       "        [  3.3892],\n",
       "        [  4.2331],\n",
       "        [  1.8521],\n",
       "        [  3.8666],\n",
       "        [  5.1376],\n",
       "        [  2.1600],\n",
       "        [  3.3500],\n",
       "        [  3.1405],\n",
       "        [  1.7720],\n",
       "        [  3.5960],\n",
       "        [  3.9094],\n",
       "        [  1.9564],\n",
       "        [ 21.9455],\n",
       "        [  2.1770],\n",
       "        [  3.8695],\n",
       "        [ 29.8398]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = 10\n",
    "desired = torch.clamp(norm, 1,  max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5.3829],\n",
       "        [ 10.0000],\n",
       "        [  5.5796],\n",
       "        [  2.5494],\n",
       "        [ 10.0000],\n",
       "        [  3.0317],\n",
       "        [  3.5005],\n",
       "        [  2.5529],\n",
       "        [  2.3500],\n",
       "        [ 10.0000],\n",
       "        [  1.5404],\n",
       "        [  4.0994],\n",
       "        [  5.8475],\n",
       "        [  3.5220],\n",
       "        [  2.8573],\n",
       "        [  2.6279],\n",
       "        [  2.3829],\n",
       "        [  2.2037],\n",
       "        [  2.3735],\n",
       "        [  5.9923],\n",
       "        [  2.4946],\n",
       "        [  3.7216],\n",
       "        [  1.7870],\n",
       "        [  3.3978],\n",
       "        [  6.1405],\n",
       "        [  3.8749],\n",
       "        [  1.5529],\n",
       "        [  2.7407],\n",
       "        [  2.2651],\n",
       "        [  2.4564],\n",
       "        [  2.7201],\n",
       "        [  2.9620],\n",
       "        [  4.9081],\n",
       "        [  1.8328],\n",
       "        [  2.8067],\n",
       "        [  2.0658],\n",
       "        [  1.7289],\n",
       "        [  2.8896],\n",
       "        [  2.7788],\n",
       "        [  4.1639],\n",
       "        [  3.2238],\n",
       "        [  4.2102],\n",
       "        [  3.3707],\n",
       "        [  3.1314],\n",
       "        [  3.7941],\n",
       "        [  1.9174],\n",
       "        [  4.4329],\n",
       "        [  2.8161],\n",
       "        [  2.3323],\n",
       "        [  3.4317],\n",
       "        [  3.6691],\n",
       "        [  4.2030],\n",
       "        [  2.2316],\n",
       "        [  2.9790],\n",
       "        [ 10.0000],\n",
       "        [ 10.0000],\n",
       "        [  3.5338],\n",
       "        [  3.9814],\n",
       "        [  4.2879],\n",
       "        [  2.4323],\n",
       "        [  4.6604],\n",
       "        [  2.4771],\n",
       "        [  2.6961],\n",
       "        [  4.1253],\n",
       "        [  1.4343],\n",
       "        [  9.5333],\n",
       "        [  6.0865],\n",
       "        [  2.3092],\n",
       "        [ 10.0000],\n",
       "        [  4.0816],\n",
       "        [  4.2610],\n",
       "        [  2.1469],\n",
       "        [  3.0179],\n",
       "        [  2.4746],\n",
       "        [  1.9371],\n",
       "        [  3.1615],\n",
       "        [ 10.0000],\n",
       "        [  3.6119],\n",
       "        [ 10.0000],\n",
       "        [  4.8073],\n",
       "        [  2.9273],\n",
       "        [  6.6919],\n",
       "        [  1.7830],\n",
       "        [  1.7167],\n",
       "        [  3.3892],\n",
       "        [  4.2331],\n",
       "        [  1.8521],\n",
       "        [  3.8666],\n",
       "        [  5.1376],\n",
       "        [  2.1600],\n",
       "        [  3.3500],\n",
       "        [  3.1405],\n",
       "        [  1.7720],\n",
       "        [  3.5960],\n",
       "        [  3.9094],\n",
       "        [  1.9564],\n",
       "        [ 10.0000],\n",
       "        [  2.1770],\n",
       "        [  3.8695],\n",
       "        [ 10.0000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = math.pow(10, -8)\n",
    "param = test_param * (desired / (eps + norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 76])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([[1, 2, 3, 4], [4, 3, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4],\n",
       "        [ 4,  3,  2,  1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2],\n",
       "        [ 3]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tel = torch.tensor([[2], [3]])\n",
    "tel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2,   4,   6,   8],\n",
       "        [ 12,   9,   6,   3]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test * tel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
